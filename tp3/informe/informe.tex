% ------ headers globales -------------
\documentclass[11pt, a4paper, twoside]{article}
\usepackage{header}
\usepackage{config}
% -------------------------------------
\begin{document}

% -- Carátula --
\clearpage{\pagestyle{empty}\input{caratula}}

\newpage
\input{introduccion}

%-- Índice --
\clearpage{%
  \pagestyle{empty}\tableofcontents%
  \vspace{3cm}%
  %\begin{abstract}
  %\end{abstract}
  \clearpage%
}
%-- A partir de aquí, pongo el contador de páginas en 1 --
\setcounter{page}{1}

\index{Implementación de Map-Reduce}
\section{Implementación de Map-Reduce}

\subsection{Encontrar el subreddit con mayor score promedio}


\begin{figure}[H]
  \caption{La función \texttt{map}}
  \centering
\begin{verbatim}
function () {
    emit(this.subreddit, { count: 1, sum: this.score} );
}
\end{verbatim}

\end{figure}

La función $map$ se aplica a cada post y emite, con el $subreddit$ como key, una tupla con la cantidad de posts - inicializada en 1 - y la suma de los scores -- inicializada con el score del post.

\begin{figure}[H]
\caption{La función \texttt{reduce}}
\centering
\begin{verbatim}
function (key, values) {
    reducedVal = {count: 0, sum: 0};
    for (var i = 0; i < values.length; i++) {
        reducedVal.count += values[i].count;
        reducedVal.sum += values[i].sum;
    };
    return reducedVal;
}
\end{verbatim}
\end{figure}

Tras aplicar la función $map$ quedan asociados cada subreddit con una lista de las tuplas asociados a los posts del subreddit. La función $reduce$ toma un fragmento de esta lista y la reduce en una sola tupla que acumula la cantidad de posts y la suma de los scores.


\begin{figure}[H]
\caption{La función \texttt{finalize}}
\centering
\begin{verbatim}
function finalize (key, reducedVal) {
    return reducedVal.sum / reducedVal.count;
}
\end{verbatim}
\end{figure}

Luego de la etapa de $reduce$, quedan asociados cada subreddit con su cantidad de posts y su suma de scores. La función $finalize$ calcula el promedio final realizando una división.

Ejecutamos el query y utilizamos la función \texttt{sort} en la consola de Mongo. El subreddit $GirlGamers$ tiene el mayor score promedio: 2483.

\newpage
\subsection{Encontrar los doce títulos con mayor score de la colección de posts con al menos 2000 votos.}

\begin{figure}[H]
\caption{La función \texttt{map}}
\centering
\begin{verbatim}
function () {
    if (this.total_votes >= 2000)
        emit(this.title, this.total_votes);
}
\end{verbatim}
\end{figure}

Se emiten, para todos los posts con al menos 2000 votos, su título y su cantidad de votos.

\begin{figure}[H]
\caption{La función \texttt{reduce}}
\centering
\begin{verbatim}
function (key, values) {
    return Array.sum(values);
}
\end{verbatim}
\end{figure}

Para cada título, se suman los votos de sus posts.

Tras ejecutar el query, se ordenaron los resultados. Los doce títulos con mayor score de la colección de posts con al menos 2000 votos son:

\begin{center}
  \begin{tabular}{l|c}
    %\hline
    \textbf{Título} & \textbf{Score} \\ \hline
    ``Airline screwed up, a friend just posted this on Facebook.'' & 177103 \\
    ``Following the Obama AMA'' & 144145 \\
    ``Nailed it.'' & 129307 \\
    ``Help a brother out!'' & 129183 \\
    ``Seen in NJ, what a friendly neighbor'' & 126222 \\
    ``McKayla Maroney visits the White House... her picture with the President'' & 120929 \\
    ``The Bus Knight'' & 119774 \\
    ``Brilliant and thoughtful parents handed these out to everyone on my flight.'' & 119232 \\
    ``Screenshot of reddit from the year 3012'' & 118866 \\
    ``Standing guard, hurricane or otherwise'' & 117272 \\
    ``My neighbors are taking this especially hard.'' & 117101 \\
    ``When I found out I could upvote by pressing 'A''' & 115717

  \end{tabular}
\end{center}

\newpage
\subsection{Para los diez mejores scores, calcular la cantidad de comentarios en promedio por sumisión.}

Este ejercicio se resuelve de manera análoga al ejercicio 1.

\begin{figure}[H]
\caption{La función \texttt{map}}
\centering
\begin{verbatim}
function () {
    emit(this.score, {count: 1, sum: this.number_of_comments});
}
\end{verbatim}
\end{figure}

\begin{figure}[H]
\caption{La función \texttt{reduce}}
\centering
\begin{verbatim}
function (key, values) {
    reducedVal = {count: 0, sum: 0};
    for (var i = 0; i < values.length; i++) {
        reducedVal.count += values[i].count;
        reducedVal.sum += values[i].sum;
    };
    return reducedVal;
}
\end{verbatim}
\end{figure}

\begin{figure}[H]
\caption{La función \texttt{finalize}}
\centering
\begin{verbatim}
function finalize (key, reducedVal) {
    return reducedVal.sum / reducedVal.count;
}
\end{verbatim}
\end{figure}

Los resultados se ordenaron. Los diez mejores scores y la cantidad de comentarios en promedio por sumisión son:

\begin{center}
  \begin{tabular}{l|c}
    %\hline
    \textbf{Score} & \textbf{Comentarios en promedio} \\ \hline
    20570 & 1463 \\
    12333 & 1612 \\
    11908 & 2681 \\
    10262 & 1514 \\
    8935 & 480 \\
    8835 & 1716 \\
    8699 & 934 \\
    8241 & 571 \\
    7297 & 1110 \\
    6741 & 2204
  \end{tabular}
\end{center}

\subsection{Entre los usuarios con a la sumo 5 sumisiones, encontrar el que posea mayor cantidad de upvotes.}

Este ejercicio se resuelve de forma similar al ejercicio 1, salvo que en la función $finalize$ se filtran los usuarios con más de 5 sumisiones.

\begin{figure}[H]
\caption{La función \texttt{map}}
\centering
\begin{verbatim}
function () {
    emit(this.username, {sumisiones: 1, number_of_upvotes: this.number_of_upvotes});
}
\end{verbatim}
\end{figure}

\begin{figure}[H]
\caption{La función \texttt{reduce}}
\centering
\begin{verbatim}
function (key, values) {
    var res = {sumisiones: 0, number_of_upvotes: 0};
    for (var i = 0; i < values.length; i++) {
        var val = values[i];
        res.sumisiones += val.sumisiones;
        res.number_of_upvotes += val.number_of_upvotes;
    }
    return res;
}
\end{verbatim}
\end{figure}

\begin{figure}[H]
\caption{La función \texttt{finalize}}
\centering
\begin{verbatim}
function finalize (key, reducedVal) {
    if (reducedVal.sumisiones <= 5)
        return reducedVal.number_of_upvotes;
}
\end{verbatim}
\end{figure}

Los resultados se ordenaron. El usuario con a lo sumo cinco sumisiones ya la mayor cantidad de upvotes es ``lepry'', con 90396 upvotes.

\newpage
\subsection{Para todos los subrredit que poseen un score entre 280 y 300, indicar la cantidad palabras
presentes nnen sus títulos}

Este ejercicio se resuelve de forma similar al ejercicio 1, salvo que en la función $finalize$ se filtran los subreddit cuyo score no se encuentra en el intervalo [280,300].

\begin{figure}[H]
\caption{La función \texttt{map}}
\centering
\begin{verbatim}
function () {
    var cantPalabras = this.title.split(' ').length;
    emit(this.subreddit, {score: this.score, cantPalabras: cantPalabras});
}
\end{verbatim}
\end{figure}

\begin{figure}[H]
\caption{La función \texttt{reduce}}
\centering
\begin{verbatim}
function (key, values) {
    var res = {score: 0, cantPalabras: 0};
    for (var i = 0; i < values.length; i++) {
        var val = values[i];
        res.score += val.score;
        res.cantPalabras += val.cantPalabras;
    }
    return res;
}
\end{verbatim}
\end{figure}

\begin{figure}[H]
\caption{La función \texttt{finalize}}
\centering
\begin{verbatim}
function finalize (key, reducedVal) {
    if (280 <= reducedVal.score && reducedVal.score <= 300)
        return reducedVal.cantPalabras;
}
\end{verbatim}
\end{figure}


Los únicos resultados arrojados fueron:

\begin{center}
  \begin{tabular}{l|c}
    %\hline
    \textbf{Subreddit} & \textbf{Palabras en títulos} \\ \hline
    ``Firearms'' & 24 \\
    ``anime'' & 18 \\
    ``Sexy'' & 13 \\
    ``Feminism'' & 6 \\
    ``HeroesofNewerth'' & 6 \\
    ``TheRealZachAnner'' & 4 \\
    ``ragecomics'' & 4 \\
    ``xkcd'' & 4 \\
  \end{tabular}
\end{center}

\clearpage
\index{Investigación}
\section{Investigación}
Para esta parte del TP se pide leer e interpretar el paper <<\textbf{Job
Scheduling for Multi- User MapReduce
Clusters}>>\footnote{http://www.icsi.berkeley.edu/pubs/techreport
s/ICSI\_jobschedulingfor09.pdf}. Se sugiere además una serie de puntos
para analizar el contenido del paper. Estos son los siguientes:

\vspace{3em}
\ref{investigacion-1} Explique cuál es el entorno y la situación donde se plantea el problema. (Motivación)

\ref{investigacion-2} Identifique de problema

\ref{investigacion-3} Identifique situaciones donde el problema se dispara y la consecuencias que esto genera.

\ref{investigacion-4} Comente el background histórico del problema

\ref{investigacion-5} Explique otros problemas asociados a la búsqueda de una mejor solución

\ref{investigacion-6} Explique las soluciones propuestas

\ref{investigacion-7} Evalúe soluciones propuestas

\ref{investigacion-8} Discusión

\ref{investigacion-9} Conclusiones

\clearpage
\subsection {\footnotesize Explique cuál es el entorno y la situación donde se plantea el problema. (Motivación)}
\label{investigacion-1}

La idea tras este paper surgió luego de que los autores se vieran frente a la
tarea de diseñar un scheduler para MapReduce, para la empresa Facebook. Este
sería el encargado de repartir el poder de cómputo en un \emph{warehouse
Hadoop}\footnote{Hadoop es la versión \emph{open-source} de MapReduce.} de 600
nodos, en un entorno multiusuario, en donde se combinarían tareas de producción
con tareas experimentales.

Este warehouse era utilizado para aproximadamente 3200 operaciones de MapReduce
diarias, siendo que algunas de ellas eran tareas frecuentes de mantenimiento,
análisis de datos, antispam y optimización, cuya ejecución se prolongaba a lo
largo de horas, mientras que otras eran queries \emph{AD-HOC} cuya ejecución
demoraba unos pocos minutos. Por tal motivo, era de vital importancia poder
lograr un mecanismo de \textbf{scheduling justo}.

\clearpage
\subsection {\footnotesize Identifique el problema}
\label{investigacion-2}

Se describen principalmente dos aspectos en donde el scheduling de un cluster
MapReduce se diferencia de un mecanismo genérico de scheduling, y por los cuales
el mecanismo de scheduling utilizado previamente presentaba una pérdida de
rendimiento de entre 2 y 10 veces en comparación con el mecanismo presentado en
el paper. Los dos principales aspectos problemáticos fueron la \emph{localidad
de datos}, y la \emph{interdependencia entre las operaciones Map y Reduce}.

\begin{center}
\textbf{Localidad de Datos}
\end{center}
Este problema comprende la necesidad inherente de la técnica MapReduce de tener
acceso local a los datos con los cuales se están trabajando. Esta necesidad se
debe principalmente a que a diferencia de los algoritmos ``\texttt{CPU-
INTENSIVE}''\footnote{Los que necesitan un gran poder de cómputo.}, el MapReduce
entra en la categoría de los denominados ``\texttt{DATA-INTENSIVE}'', es decir,
aquellos en donde el poder de cómputo necesario es despreciable frente a la gran
cantidad de datos con los que se trabaja.

Desde esta perspectiva, contar con un scheduler eficiente en el acceso y la
utilización de los datos, es mucho más importante que en otro tipo de
situaciones. Todo esto está agravado por el costo que supone el almacenamiento,
y la transmisión de datos entre distintos servidores. Este defecto se puede
observar principalmente en \textbf{trabajos pequeños y/o concurrentes}.


\begin{center}
\textbf{Interdependencia}
\end{center}
Se entiende por interdependencia a la necesidad de que todas las tareas de
\texttt{map} se encuentren finalizadas al momento de iniciar la ejecución de
\texttt{reduce}. Es fácil percibir la gran cantidad de inconvenientes que esto
genera. Se mencionan particularmente los casos de \textbf{infrautilización de
los recursos y \texttt{starvation}}, en donde se da que una única tarea adquiere
cierta cantidad de slots, destinados a realizar la operación \texttt{reduce},
pero que se ven bloqueados/inutilizados hasta el momento en que esta tarea
termine de realizar su operación de \texttt{map}, evitando de esta forma que
otras tareas se ejecuten, y de \textbf{consumo excesivo de espacio de disco}
destinado a los datos intermedios producidos por \texttt{map} (datos que no
pueden ser liberados hasta que el trabajo termine).

\clearpage
\subsection {\footnotesize Identifique situaciones donde el problema se dispara y la consecuencias que esto genera.}
\label{investigacion-3}

Los problemas descriptos anteriormente se ponían en evidencia al momento de
querer realizar queries \texttt{ad-hoc} de muy corta duración frente a los
trabajos de producción que el warehouse debe correr periódicamente. Bajo esta
perspectiva, era deseable que los trabajos experimentales puedan ser lanzados
en cualquier momento, y tener un tiempo de respuesta \textbf{aceptable}. Con
la implementación del Scheduler FIFO de Hadoop, esto se volvía imposible,
reduciendo significativamente la utilidad del sistema.

\fixme


\clearpage


\subsection {\footnotesize Comente el background histórico del problema}
\label{investigacion-4}
Hadoop está inspirado en el MapReduce de Google, por lo que gran parte de su
implementación básica está fuertemente ligada a este proyecto. La primer
solución al conflicto del scheduling, se encuentra provista por defecto dentro
la propia implementación de Hadoop, y consta de una cola \texttt{FIFO} de 5
niveles de prioridad, de forma tal que cada vez que un slot se libera, el
scheduler lo asigna a la más prioritaria de entre las tareas pendientes.

Sobre este enfoque, Hadoop aplica una \texttt{optimización de localidad}, al
igual que lo hace MapReduce de Google: dado que una tarea generalmente consta de
múltiples operaciones de \texttt{map}, luego de elegir una tarea el scheduler
selecciona las operaciones map más adecuadas según un \textbf{criterio de
localidad}. Serán elegidos entonces los maps que utilicen datos que se
encuentren más cerca físicamente al worker que está corriendo la tarea. Es
decir, serán elegidas primero las que se encuentren en ese mismo worker, luego
las que se encuentren en el mismo rack, y finalmente las que se encuentren en
racks remotos.

La gran desventaja del scheduler \texttt{FIFO} es el pésimo tiempo de respuesta
para trabajos pequeños cuando se encuentran intercalados con trabajos grandes.
Por ello, la primer solución que se implementó, es el mecanismo denominado
\textbf{Hadoop On Demand (HOP)}.

\fixme

\clearpage
\subsection {\footnotesize Explique otros problemas asociados a la búsqueda de una mejor solución}
\label{investigacion-5}

Para explicar el problema, es necesario ahondar un poco en los conceptos
utilizados en el paper. Se describe un \texttt{job} como un conjunto de
\texttt{tasks}, siendo un task una operación \texttt{map-reduce}. Cada nodo
(también llamados \texttt{slaves} o \texttt{workers}) tiene una determinada
cantidad de \texttt{slots de ejecución}, y conforme estos se van liberando el
Scheduler le va asignando \texttt{tasks}, siendo que cada uno de estos ocupa
un \texttt{slot}. 

Problemas asociados a la Localidad de Datos:
\textbf{Head-of-line scheduling}: Para explicar este concepto, el paper propone
una métrica, \textbf{el porcentaje de localidad\footnote{En el paper se
distingue entre localidad de nodo y localidad de rack; la idea sigue siendo la
misma.} de un job en relación a su tamaño}. Utilizando esta métrica, dado un
\texttt{job}, su porcentaje de localidad se ve representado por la cantidad de
\texttt{nodos} en la que se encuentran distribuídos los datos de sus
\texttt{tasks}, en relación al total. Se hace notar que el \texttt{porcentaje
de localidad de un job} crece en relación a su tamaño (medido en cantidad de
\texttt{tasks}), de forma tal que un \texttt{job} pequeño tiene mucha menos
\texttt{localidad} que un \texttt{job} grande. Por otro lado, dado que se
utiliza una cola \texttt{FIFO}, el siguiente \texttt{job} a ejecutar se
encuentra de cierta forma \emph{predeterminado}, por lo que no es posible
``elegir el más apropiado''.

Asi, dado un \texttt{nodo} cualquiera al que se le hayan liberado uno o más
\texttt{slots}, la probabilidad de que el siguiente \texttt{job} contenga un
\texttt{task} cuyos datos se encuentren en ese \texttt{nodo}, es proporcional al
tamaño del \texttt{job}. Y esto ocasiona problemas en los \texttt{jobs}
pequeños, los cuales suelen ser justamente los que más necesidad de
\textbf{interactividad} tienen.

\textbf{Sticky Slots}:

Problemas asociados a la Interdependencia de Map-Reduce:


\clearpage
\subsection {\footnotesize Explique las soluciones propuestas}
\label{investigacion-6}

\clearpage
\subsection {\footnotesize Evalúe soluciones propuestas}
\label{investigacion-7}

\clearpage
\subsection {\footnotesize Discusión}
\label{investigacion-8}

\clearpage
\subsection {\footnotesize Conclusiones}
\label{investigacion-9}

\clearpage

\end{document}
